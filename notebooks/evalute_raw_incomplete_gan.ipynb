{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/ubuntu\")\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from latent_3d_points.src.ae_templates import mlp_architecture_ala_iclr_18, default_train_params\n",
    "from latent_3d_points.src.point_net_ae import PointNetAutoEncoder\n",
    "\n",
    "from latent_3d_points.src.autoencoder import Configuration as Conf\n",
    "from latent_3d_points.src.neural_net import MODEL_SAVER_ID\n",
    "\n",
    "from latent_3d_points.src.in_out import snc_category_to_synth_id, create_dir, PointCloudDataSet,\\\n",
    "        load_all_point_clouds_under_folder, pickle_data, unpickle_data\n",
    "\n",
    "from latent_3d_points.src.general_utils import plot_3d_point_cloud\n",
    "from latent_3d_points.src.tf_utils import reset_tf_graph\n",
    "\n",
    "from latent_3d_points.src.vanilla_gan import Vanilla_GAN\n",
    "from latent_3d_points.src.w_gan_gp import W_GAN_GP\n",
    "from latent_3d_points.src.generators_discriminators import point_cloud_generator,mlp_discriminator, leaky_relu, conditional_point_cloud_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DATA = (5422, 3996, 3)\n"
     ]
    }
   ],
   "source": [
    "# Use to save Neural-Net check-points etc.\n",
    "top_out_dir = '../data/'\n",
    "\n",
    "# Top-dir of where point-clouds are stored.\n",
    "top_in_dir = '../data/shape_net_core_uniform_samples_2048/'\n",
    "\n",
    "experiment_name = 'raw_gan_incomplete'\n",
    "\n",
    "n_pc_points = 2048                # Number of points per model.\n",
    "bneck_size = 128                  # Bottleneck-AE size\n",
    "ae_loss = 'chamfer'                   # Loss to optimize: 'emd' or 'chamfer'\n",
    "# class_name = raw_input('Give me the class name (e.g. \"chair\"): ').lower()\n",
    "class_name = 'chair'\n",
    "\n",
    "# all_pc_data = load_all_point_clouds_under_folder(class_dir, n_threads=8, file_ending='.ply', verbose=True)\n",
    "train_pkl = unpickle_data('/home/ubuntu/latent_3d_points/data/missing_points_dataset/train_data.pkl')\n",
    "train_data = next(train_pkl)\n",
    "\n",
    "val_pkl = unpickle_data('/home/ubuntu/latent_3d_points/data/missing_points_dataset/val_data.pkl')\n",
    "val_data = next(val_pkl)\n",
    "\n",
    "print 'Shape of DATA =', train_data.point_clouds.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Encoder\n",
      "encoder_conv_layer_0 conv params =  256 bnorm params =  128\n",
      "Tensor(\"raw_gan_incomplete_1/generator/Relu:0\", shape=(?, 1948, 64), dtype=float32)\n",
      "output size: 124672 \n",
      "\n",
      "encoder_conv_layer_1 conv params =  8320 bnorm params =  256\n",
      "Tensor(\"raw_gan_incomplete_1/generator/Relu_1:0\", shape=(?, 1948, 128), dtype=float32)\n",
      "output size: 249344 \n",
      "\n",
      "encoder_conv_layer_2 conv params =  16512 bnorm params =  256\n",
      "Tensor(\"raw_gan_incomplete_1/generator/Relu_2:0\", shape=(?, 1948, 128), dtype=float32)\n",
      "output size: 249344 \n",
      "\n",
      "encoder_conv_layer_3 conv params =  33024 bnorm params =  512\n",
      "Tensor(\"raw_gan_incomplete_1/generator/Relu_3:0\", shape=(?, 1948, 256), dtype=float32)\n",
      "output size: 498688 \n",
      "\n",
      "encoder_conv_layer_4 conv params =  32896 bnorm params =  256\n",
      "Tensor(\"raw_gan_incomplete_1/generator/Relu_4:0\", shape=(?, 1948, 128), dtype=float32)\n",
      "output size: 249344 \n",
      "\n",
      "Tensor(\"raw_gan_incomplete_1/generator/Max:0\", shape=(?, 128), dtype=float32)\n",
      "Building Decoder\n",
      "decoder_fc_0 FC params =  33024 Tensor(\"raw_gan_incomplete_1/generator/Relu_5:0\", shape=(?, 256), dtype=float32)\n",
      "output size: 256 \n",
      "\n",
      "decoder_fc_1 FC params =  65792 Tensor(\"raw_gan_incomplete_1/generator/Relu_6:0\", shape=(?, 256), dtype=float32)\n",
      "output size: 256 \n",
      "\n",
      "decoder_fc_2 FC params =  1579008 Tensor(\"raw_gan_incomplete_1/generator/decoder_fc_2/BiasAdd:0\", shape=(?, 6144), dtype=float32)\n",
      "output size: 6144 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "use_wgan = True     # Wasserstein with gradient penalty, or not?\n",
    "n_epochs = 10       # Epochs to train.\n",
    "\n",
    "plot_train_curve = True\n",
    "save_gan_model = True\n",
    "saver_step = np.hstack([np.array([1, 5, 10]), np.arange(50, n_epochs + 1, 50)])\n",
    "\n",
    "# If true, every 'saver_step' epochs we produce & save synthetic pointclouds.\n",
    "save_synthetic_samples = True\n",
    "# How many synthetic samples to produce at each save step.\n",
    "n_syn_samples = train_data.num_examples\n",
    "\n",
    "# Optimization parameters\n",
    "init_lr = 0.0001\n",
    "batch_size = 50\n",
    "noise_params = {'mu':0, 'sigma': 0.2}\n",
    "# noise_dim = 128\n",
    "noise_dim = 1948 # incomplete shape: 2048 - 100 - 1948\n",
    "beta = 0.5 # ADAM's momentum.\n",
    "\n",
    "n_out = [n_pc_points, 3] # Dimensionality of generated samples.\n",
    "\n",
    "discriminator = mlp_discriminator\n",
    "# generator = point_cloud_generator\n",
    "train_params = default_train_params() # not actually used\n",
    "encoder, decoder, enc_args, dec_args = mlp_architecture_ala_iclr_18(n_pc_points, bneck_size)\n",
    "\n",
    "conf = Conf(n_input = [1948, 3],\n",
    "            loss = ae_loss,\n",
    "            training_epochs = train_params['training_epochs'], # not actually used\n",
    "            batch_size = train_params['batch_size'],\n",
    "            denoising = train_params['denoising'],\n",
    "            learning_rate = train_params['learning_rate'],\n",
    "            train_dir = top_out_dir,\n",
    "            loss_display_step = train_params['loss_display_step'],\n",
    "            saver_step = train_params['saver_step'],\n",
    "            z_rotate = train_params['z_rotate'],\n",
    "            encoder = encoder,\n",
    "            decoder = decoder,\n",
    "            encoder_args = enc_args,\n",
    "            decoder_args = dec_args,\n",
    "            n_output = [2048, 3]\n",
    "           )\n",
    "conf.experiment_name = experiment_name\n",
    "generator = conditional_point_cloud_generator\n",
    "\n",
    "lam = 10\n",
    "disc_kwargs = {'b_norm': False}\n",
    "gan = W_GAN_GP(experiment_name, init_lr, lam, n_out, noise_dim,\\\n",
    "                discriminator, generator, conf,\\\n",
    "                disc_kwargs=disc_kwargs, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = '/home/ubuntu/latent_3d_points/data/OUT/raw_gan/raw_gan_incomplete'\n",
    "# epoch = 10\n",
    "# gan.restore_model(model_path, epoch, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/home/ubuntu/latent_3d_points/data/OUT/synthetic_samples/raw_gan_incomplete/epoch_0.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-fe80b35530e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnpy_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/ubuntu/latent_3d_points/data/OUT/synthetic_samples/raw_gan_incomplete/epoch_0.npz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msyn_data_npz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpy_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msyn_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyn_data_npz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arr_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyn_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/ubuntu/latent_3d_points/data/OUT/synthetic_samples/raw_gan_incomplete/epoch_0.npz'"
     ]
    }
   ],
   "source": [
    "npy_file = \"/home/ubuntu/latent_3d_points/data/OUT/synthetic_samples/raw_gan_incomplete/epoch_0.npz\"\n",
    "syn_data_npz = np.load(npy_file)\n",
    "syn_data = syn_data_npz['arr_0']\n",
    "print(syn_data.shape)\n",
    "\n",
    "for k in range(3):  # plot three (synthetic) random examples.\n",
    "    plot_3d_point_cloud(syn_data[k][:, 0], syn_data[k][:, 1], syn_data[k][:, 2],\\\n",
    "                       in_u_sphere=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
