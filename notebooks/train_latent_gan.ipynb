{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook will help you train a latent Point-Cloud GAN.\n",
    "\n",
    "(Assumes latent_3d_points is in the PYTHONPATH and that a trained AE model exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/ubuntu\")\n",
    "\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from latent_3d_points.src.point_net_ae import PointNetAutoEncoder\n",
    "from latent_3d_points.src.autoencoder import Configuration as Conf\n",
    "from latent_3d_points.src.neural_net import MODEL_SAVER_ID\n",
    "\n",
    "from latent_3d_points.src.in_out import snc_category_to_synth_id, create_dir, PointCloudDataSet, \\\n",
    "                                        load_all_point_clouds_under_folder\n",
    "\n",
    "from latent_3d_points.src.general_utils import plot_3d_point_cloud\n",
    "from latent_3d_points.src.tf_utils import reset_tf_graph\n",
    "\n",
    "from latent_3d_points.src.vanilla_gan import Vanilla_GAN\n",
    "from latent_3d_points.src.w_gan_gp import W_GAN_GP\n",
    "from latent_3d_points.src.generators_discriminators import latent_code_discriminator_two_layers,\\\n",
    "latent_code_generator_two_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify where the raw point-clouds and the pre-trained AE are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-dir of where point-clouds are stored.\n",
    "top_in_dir = '../data/shape_net_core_uniform_samples_2048/'    \n",
    "\n",
    "ae_configuration = '../data/single_class_ae/configuration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me the class name (e.g. \"chair\"): chair\n"
     ]
    }
   ],
   "source": [
    "# Where to save GANs check-points etc.\n",
    "top_out_dir = '../data/'\n",
    "experiment_name = 'latent_gan_with_chamfer_ae'\n",
    "\n",
    "ae_epoch = 500           # Epoch of AE to load.\n",
    "bneck_size = 128         # Bottleneck-size of the AE\n",
    "n_pc_points = 2048       # Number of points per model.\n",
    "\n",
    "class_name = raw_input('Give me the class name (e.g. \"chair\"): ').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6778 pclouds were loaded. They belong in 1 shape-classes.\n",
      "Shape of DATA = (6778, 2048, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load point-clouds.\n",
    "syn_id = snc_category_to_synth_id()[class_name]\n",
    "class_dir = osp.join(top_in_dir , syn_id)\n",
    "all_pc_data = load_all_point_clouds_under_folder(class_dir, n_threads=8, file_ending='.ply', verbose=True)\n",
    "print 'Shape of DATA =', all_pc_data.point_clouds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '../data/single_class_ae/configuration.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-37a0d2f5be49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load pre-trained AE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mreset_tf_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mae_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mae_configuration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mae_conf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'verbose'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mae_conf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'verbose'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/latent_3d_points/src/autoencoder.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0munpickle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/latent_3d_points/src/in_out.pyc\u001b[0m in \u001b[0;36munpickle_data\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m     62\u001b[0m     '''Restore data previously saved with pickle_data().\n\u001b[1;32m     63\u001b[0m     '''\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0minFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '../data/single_class_ae/configuration.pickle'"
     ]
    }
   ],
   "source": [
    "# Load pre-trained AE\n",
    "reset_tf_graph()\n",
    "ae_conf = Conf.load(ae_configuration)\n",
    "ae_conf.encoder_args['verbose'] = False\n",
    "ae_conf.decoder_args['verbose'] = False\n",
    "ae = PointNetAutoEncoder(ae_conf.experiment_name, ae_conf)\n",
    "ae.restore_model(ae_conf.train_dir, ae_epoch, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use AE to convert raw pointclouds to latent codes.\n",
    "latent_codes = ae.get_latent_codes(all_pc_data.point_clouds)\n",
    "latent_data = PointCloudDataSet(latent_codes)\n",
    "print 'Shape of DATA =', latent_data.point_clouds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the decoded AE latent-codes look descent.\n",
    "L = ae.decode(latent_codes)\n",
    "i = 0\n",
    "plot_3d_point_cloud(L[i][:, 0], L[i][:, 1], L[i][:, 2], in_u_sphere=True);\n",
    "i = 20\n",
    "plot_3d_point_cloud(L[i][:, 0], L[i][:, 1], L[i][:, 2], in_u_sphere=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GAN parameters.\n",
    "\n",
    "use_wgan = True     # Wasserstein with gradient penalty, or not?\n",
    "n_epochs = 1        # Epochs to train.\n",
    "\n",
    "plot_train_curve = True\n",
    "save_gan_model = False\n",
    "saver_step = np.hstack([np.array([1, 5, 10]), np.arange(50, n_epochs + 1, 50)])\n",
    "\n",
    "# If true, every 'saver_step' epochs we produce & save synthetic pointclouds.\n",
    "save_synthetic_samples = True\n",
    "# How many synthetic samples to produce at each save step.\n",
    "n_syn_samples = latent_data.num_examples\n",
    "\n",
    "# Optimization parameters\n",
    "init_lr = 0.0001\n",
    "batch_size = 50\n",
    "noise_params = {'mu':0, 'sigma': 0.2}\n",
    "noise_dim = bneck_size\n",
    "beta = 0.5 # ADAM's momentum.\n",
    "\n",
    "n_out = [bneck_size] # Dimensionality of generated samples.\n",
    "\n",
    "if save_synthetic_samples:\n",
    "    synthetic_data_out_dir = osp.join(top_out_dir, 'OUT/synthetic_samples/', experiment_name)\n",
    "    create_dir(synthetic_data_out_dir)\n",
    "\n",
    "if save_gan_model:\n",
    "    train_dir = osp.join(top_out_dir, 'OUT/latent_gan', experiment_name)\n",
    "    create_dir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_tf_graph()\n",
    "\n",
    "if use_wgan:\n",
    "    lam = 10 # lambda of W-GAN-GP\n",
    "    gan = W_GAN_GP(experiment_name, init_lr, lam, n_out, noise_dim, \\\n",
    "                  latent_code_discriminator_two_layers, \n",
    "                  latent_code_generator_two_layers,\\\n",
    "                  beta=beta)\n",
    "else:    \n",
    "    gan = Vanilla_GAN(experiment_name, init_lr, n_out, noise_dim,\n",
    "                     latent_code_discriminator_two_layers, latent_code_generator_two_layers,\n",
    "                     beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accum_syn_data = []\n",
    "train_stats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the GAN.\n",
    "for _ in range(n_epochs):\n",
    "    loss, duration = gan._single_epoch_train(latent_data, batch_size, noise_params)\n",
    "    epoch = int(gan.sess.run(gan.increment_epoch))\n",
    "    print epoch, loss\n",
    "\n",
    "    if save_gan_model and epoch in saver_step:\n",
    "        checkpoint_path = osp.join(train_dir, MODEL_SAVER_ID)\n",
    "        gan.saver.save(gan.sess, checkpoint_path, global_step=gan.epoch)\n",
    "\n",
    "    if save_synthetic_samples and epoch in saver_step:\n",
    "        syn_latent_data = gan.generate(n_syn_samples, noise_params)\n",
    "        syn_data = ae.decode(syn_latent_data)\n",
    "        np.savez(osp.join(synthetic_data_out_dir, 'epoch_' + str(epoch)), syn_data)\n",
    "        for k in range(3):  # plot three (syntetic) random examples.\n",
    "            plot_3d_point_cloud(syn_data[k][:, 0], syn_data[k][:, 1], syn_data[k][:, 2],\n",
    "                               in_u_sphere=True)\n",
    "\n",
    "    train_stats.append((epoch, ) + loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if plot_train_curve:\n",
    "    x = range(len(train_stats))\n",
    "    d_loss = [t[1] for t in train_stats]\n",
    "    g_loss = [t[2] for t in train_stats]\n",
    "    plt.plot(x, d_loss, '--')\n",
    "    plt.plot(x, g_loss)\n",
    "    plt.title('Latent GAN training. (%s)' %(class_name))\n",
    "    plt.legend(['Discriminator', 'Generator'], loc=0)\n",
    "    \n",
    "    plt.tick_params(axis='x', which='both', bottom='off', top='off')\n",
    "    plt.tick_params(axis='y', which='both', left='off', right='off')\n",
    "    \n",
    "    plt.xlabel('Epochs.') \n",
    "    plt.ylabel('Loss.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
